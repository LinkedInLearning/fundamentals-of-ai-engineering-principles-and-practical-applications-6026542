{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 16 sample documents\n",
      "Converted documents to nodes\n",
      "Created BM25 retriever\n",
      "\n",
      "=== Testing BM25 Retriever ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Retrieved 5 documents in 0.0031 seconds\n",
      "1. Score: 1.7306 - Machine learning is a subset of artificial intelligence that enables systems to learn from data.\n",
      "2. Score: 1.6152 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "3. Score: 0.9407 - Transformers are deep learning models that use self-attention mechanisms to process sequential data.\n",
      "4. Score: 0.8661 - Deep learning uses neural networks with many layers to extract high-level features from data.\n",
      "5. Score: 0.6322 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "\n",
      "Setting up vector search with bi-encoder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e4f27fe2c040f29ea6d5817603e6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf847261feb2450fa639fb693be47d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7322f826a4b4c8099cff7e93ac5fc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de19bbdb984e448a9d06ac27c5c4944f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32ccfa56e9644d3b1fb9f4414de1c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2695bcfc60a43df8992236dc4938015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4f5eb089df4031b7e2abc56d3bed64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561ca06467864058b85f71abe8f00a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2a21cb1d914449ad4ecfae319959f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522d645958ce44fead980097fac72e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7896f5bfd65b4115a6f7302b4181e239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector retriever\n",
      "\n",
      "=== Testing Vector Retriever ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Retrieved 5 documents in 0.0153 seconds\n",
      "1. Score: 0.6398 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "2. Score: 0.5692 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "3. Score: 0.5632 - Machine learning is a subset of artificial intelligence that enables systems to learn from data.\n",
      "4. Score: 0.4787 - The pandas library provides data structures and tools for data manipulation and analysis in Python.\n",
      "5. Score: 0.4156 - Natural language processing (NLP) helps computers understand, interpret, and manipulate human language.\n",
      "\n",
      "Created simple fusion retriever\n",
      "\n",
      "=== Testing Simple Fusion Retriever ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Retrieved 7 documents in 0.0132 seconds\n",
      "1. Score: 0.6322 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "2. Score: 1.6152 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "3. Score: 1.7306 - Machine learning is a subset of artificial intelligence that enables systems to learn from data.\n",
      "4. Score: 0.4787 - The pandas library provides data structures and tools for data manipulation and analysis in Python.\n",
      "5. Score: 0.4156 - Natural language processing (NLP) helps computers understand, interpret, and manipulate human language.\n",
      "6. Score: 0.9407 - Transformers are deep learning models that use self-attention mechanisms to process sequential data.\n",
      "7. Score: 0.8661 - Deep learning uses neural networks with many layers to extract high-level features from data.\n",
      "\n",
      "Created weighted fusion retriever\n",
      "\n",
      "=== Testing Weighted Fusion Retriever ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Retrieved 7 documents in 0.0130 seconds\n",
      "1. Score: 0.9134 - Machine learning is a subset of artificial intelligence that enables systems to learn from data.\n",
      "2. Score: 0.8830 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "3. Score: 0.6375 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "4. Score: 0.3351 - The pandas library provides data structures and tools for data manipulation and analysis in Python.\n",
      "5. Score: 0.2909 - Natural language processing (NLP) helps computers understand, interpret, and manipulate human language.\n",
      "6. Score: 0.2822 - Transformers are deep learning models that use self-attention mechanisms to process sequential data.\n",
      "7. Score: 0.2598 - Deep learning uses neural networks with many layers to extract high-level features from data.\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "\n",
      "Created reranked retriever\n",
      "\n",
      "=== Testing Reranked Retriever ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Retrieved 5 documents in 0.2196 seconds\n",
      "1. Score: 4.9707 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "2. Score: 0.4729 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "3. Score: -1.9425 - Machine learning is a subset of artificial intelligence that enables systems to learn from data.\n",
      "4. Score: -3.8818 - The pandas library provides data structures and tools for data manipulation and analysis in Python.\n",
      "5. Score: -6.3813 - Deep learning uses neural networks with many layers to extract high-level features from data.\n",
      "Created configurable retrieval pipeline\n",
      "\n",
      "Building retrieval pipeline...\n",
      "- Added BM25 retriever\n",
      "- Added vector retriever\n",
      "- Added weighted fusion for hybrid retrieval\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "- Added cross-encoder reranker\n",
      "Pipeline build complete!\n",
      "\n",
      "=== Retrieval Results ===\n",
      "Query: 'How can Python be used for natural language processing?'\n",
      "Retrieved 5 documents in 0.0849 seconds\n",
      "1. Score: 0.6935 - Natural language processing (NLP) helps computers understand, interpret, and manipulate human language.\n",
      "2. Score: -1.5628 - Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\n",
      "3. Score: -1.8753 - Python is a high-level, interpreted programming language known for its readability and simplicity.\n",
      "4. Score: -5.9148 - The pandas library provides data structures and tools for data manipulation and analysis in Python.\n",
      "5. Score: -10.6206 - GPT models are autoregressive language models that use transformer architectures.\n",
      "\n",
      "=== Pipeline Configuration Comparison ===\n",
      "Query: 'What are transformer models used for in NLP?'\n",
      "\n",
      "Testing configuration: BM25 Only\n",
      "Created configurable retrieval pipeline\n",
      "\n",
      "Building retrieval pipeline...\n",
      "- Added BM25 retriever\n",
      "- Using bm25 as base retriever\n",
      "Pipeline build complete!\n",
      "Retrieved 5 documents in 0.0009 seconds\n",
      "Top result: GPT models are autoregressive language models that use transformer architectures....\n",
      "\n",
      "Testing configuration: Vector Only\n",
      "Created configurable retrieval pipeline\n",
      "\n",
      "Building retrieval pipeline...\n",
      "- Added vector retriever\n",
      "- Using vector as base retriever\n",
      "Pipeline build complete!\n",
      "Retrieved 5 documents in 0.0159 seconds\n",
      "Top result: BERT is a transformer-based language model pre-trained on large text corpora....\n",
      "\n",
      "Testing configuration: Hybrid (No Reranking)\n",
      "Created configurable retrieval pipeline\n",
      "\n",
      "Building retrieval pipeline...\n",
      "- Added BM25 retriever\n",
      "- Added vector retriever\n",
      "- Added weighted fusion for hybrid retrieval\n",
      "Pipeline build complete!\n",
      "Retrieved 6 documents in 0.0170 seconds\n",
      "Top result: GPT models are autoregressive language models that use transformer architectures....\n",
      "\n",
      "Testing configuration: Complete Pipeline\n",
      "Created configurable retrieval pipeline\n",
      "\n",
      "Building retrieval pipeline...\n",
      "- Added BM25 retriever\n",
      "- Added vector retriever\n",
      "- Added weighted fusion for hybrid retrieval\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "- Added cross-encoder reranker\n",
      "Pipeline build complete!\n",
      "Retrieved 5 documents in 0.0767 seconds\n",
      "Top result: GPT models are autoregressive language models that use transformer architectures....\n",
      "\n",
      "=== Summary ===\n",
      "BM25 Only: 0.0009s, 5 results\n",
      "Vector Only: 0.0159s, 5 results\n",
      "Hybrid (No Reranking): 0.0170s, 6 results\n",
      "Complete Pipeline: 0.0767s, 5 results\n",
      "\n",
      "Retrieval pipeline notebook complete!\n"
     ]
    }
   ],
   "source": [
    "# Complete Retrieval Pipeline: From Basic to Advanced Techniques\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core.schema import Document, NodeWithScore, QueryBundle, TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Hugging Face imports\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "## 2. Create Sample Documents\n",
    "\n",
    "def create_sample_documents():\n",
    "    \"\"\"Create a set of sample documents for demonstration.\"\"\"\n",
    "    texts = [\n",
    "        \"Python is a high-level, interpreted programming language known for its readability and simplicity.\",\n",
    "        \"Machine learning is a subset of artificial intelligence that enables systems to learn from data.\",\n",
    "        \"Neural networks are computing systems inspired by biological neural networks in animal brains.\",\n",
    "        \"Deep learning uses neural networks with many layers to extract high-level features from data.\",\n",
    "        \"Natural language processing (NLP) helps computers understand, interpret, and manipulate human language.\",\n",
    "        \"Transformers are deep learning models that use self-attention mechanisms to process sequential data.\",\n",
    "        \"BERT is a transformer-based language model pre-trained on large text corpora.\",\n",
    "        \"GPT models are autoregressive language models that use transformer architectures.\",\n",
    "        \"Python libraries like PyTorch and TensorFlow are widely used for deep learning development.\",\n",
    "        \"The pandas library provides data structures and tools for data manipulation and analysis in Python.\",\n",
    "        \"LlamaIndex is a data framework for LLM applications to connect custom data sources to language models.\",\n",
    "        \"Hybrid search combines multiple retrieval methods to improve search quality.\",\n",
    "        \"BM25 is a bag-of-words retrieval function used in information retrieval.\",\n",
    "        \"Vector search finds documents by measuring similarity in embedding space.\",\n",
    "        \"Reranking is a two-stage process that refines initial search results with a more complex model.\",\n",
    "        \"Retrieval pipelines often combine multiple techniques to achieve the best search results.\"\n",
    "    ]\n",
    "    \n",
    "    documents = []\n",
    "    for i, text in enumerate(texts):\n",
    "        doc = Document(text=text, id_=f\"doc_{i}\")\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Create the documents\n",
    "documents = create_sample_documents()\n",
    "print(f\"Created {len(documents)} sample documents\")\n",
    "\n",
    "# Convert documents to nodes\n",
    "nodes = [TextNode(text=doc.text, id_=doc.id_) for doc in documents]\n",
    "print(\"Converted documents to nodes\")\n",
    "\n",
    "## 3. Basic BM25 Retriever\n",
    "\n",
    "# Set up basic BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=5)\n",
    "print(\"Created BM25 retriever\")\n",
    "\n",
    "def test_retriever(retriever, query_text, name=\"Retriever\"):\n",
    "    \"\"\"Test a retriever with a query and print results.\"\"\"\n",
    "    print(f\"\\n=== Testing {name} ===\")\n",
    "    start_time = time.time()\n",
    "    query_bundle = QueryBundle(query_text)\n",
    "    results = retriever.retrieve(query_bundle)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(f\"Retrieved {len(results)} documents in {(end_time - start_time):.4f} seconds\")\n",
    "    \n",
    "    for i, node in enumerate(results, 1):\n",
    "        print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test BM25 retriever\n",
    "query = \"How is Python used in machine learning?\"\n",
    "bm25_results = test_retriever(bm25_retriever, query, \"BM25 Retriever\")\n",
    "\n",
    "## 4. Vector Search Retriever\n",
    "\n",
    "# Set up bi-encoder for vector search\n",
    "print(\"\\nSetting up vector search with bi-encoder...\")\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bi_encoder = SentenceTransformer(model_name, device=\"cpu\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=model_name)\n",
    "\n",
    "# Create embeddings for nodes\n",
    "for node in nodes:\n",
    "    text = node.get_content()\n",
    "    embedding = bi_encoder.encode(text)\n",
    "    node.embedding = embedding\n",
    "\n",
    "# Create vector index\n",
    "vector_index = VectorStoreIndex(nodes=nodes, embed_model=embed_model)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=5)\n",
    "print(\"Created vector retriever\")\n",
    "\n",
    "# Test vector retriever\n",
    "vector_results = test_retriever(vector_retriever, query, \"Vector Retriever\")\n",
    "\n",
    "## 5. Simple Fusion Retriever\n",
    "\n",
    "class SimpleFusionRetriever(BaseRetriever):\n",
    "    \"\"\"Simple fusion retriever that combines results from multiple retrievers.\"\"\"\n",
    "    \n",
    "    def __init__(self, retrievers: Dict[str, BaseRetriever]):\n",
    "        \"\"\"Initialize with retrievers dictionary.\"\"\"\n",
    "        self.retrievers = retrievers\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "        all_nodes = {}\n",
    "        \n",
    "        for name, retriever in self.retrievers.items():\n",
    "            results = retriever.retrieve(query_bundle)\n",
    "            \n",
    "            # Add to results dictionary (keyed by node_id for deduplication)\n",
    "            for node in results:\n",
    "                all_nodes[node.node.node_id] = node\n",
    "        \n",
    "        # Return all unique nodes\n",
    "        return list(all_nodes.values())\n",
    "\n",
    "# Create simple fusion retriever\n",
    "simple_fusion_retriever = SimpleFusionRetriever(\n",
    "    retrievers={\"vector\": vector_retriever, \"bm25\": bm25_retriever}\n",
    ")\n",
    "print(\"\\nCreated simple fusion retriever\")\n",
    "\n",
    "# Test simple fusion retriever\n",
    "simple_fusion_results = test_retriever(simple_fusion_retriever, query, \"Simple Fusion Retriever\")\n",
    "\n",
    "## 6. Weighted Fusion Retriever\n",
    "\n",
    "class WeightedFusionRetriever(BaseRetriever):\n",
    "    \"\"\"Weighted fusion retriever that combines and rescores results.\"\"\"\n",
    "    \n",
    "    def __init__(self, retrievers: Dict[str, BaseRetriever], weights: Dict[str, float]):\n",
    "        \"\"\"Initialize with retrievers and weights.\"\"\"\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes with weighted fusion approach.\"\"\"\n",
    "        all_results = {}\n",
    "        \n",
    "        for name, retriever in self.retrievers.items():\n",
    "            results = retriever.retrieve(query_bundle)\n",
    "            weight = self.weights.get(name, 1.0)\n",
    "            \n",
    "            for node_with_score in results:\n",
    "                node_id = node_with_score.node.node_id\n",
    "                weighted_score = node_with_score.score * weight\n",
    "                \n",
    "                if node_id not in all_results:\n",
    "                    all_results[node_id] = {\n",
    "                        \"node\": node_with_score.node,\n",
    "                        \"scores\": {}\n",
    "                    }\n",
    "                all_results[node_id][\"scores\"][name] = weighted_score\n",
    "        \n",
    "        final_results = []\n",
    "        for node_id, data in all_results.items():\n",
    "            combined_score = sum(data[\"scores\"].values())\n",
    "            node_with_score = NodeWithScore(\n",
    "                node=data[\"node\"],\n",
    "                score=combined_score\n",
    "            )\n",
    "            final_results.append(node_with_score)\n",
    "        \n",
    "        final_results.sort(key=lambda x: x.score, reverse=True)\n",
    "        return final_results\n",
    "\n",
    "# Create weighted fusion retriever\n",
    "weighted_fusion_retriever = WeightedFusionRetriever(\n",
    "    retrievers={\"vector\": vector_retriever, \"bm25\": bm25_retriever},\n",
    "    weights={\"vector\": 0.7, \"bm25\": 0.3}\n",
    ")\n",
    "print(\"\\nCreated weighted fusion retriever\")\n",
    "\n",
    "# Test weighted fusion retriever\n",
    "weighted_fusion_results = test_retriever(weighted_fusion_retriever, query, \"Weighted Fusion Retriever\")\n",
    "\n",
    "## 7. Reranker with Cross-Encoder\n",
    "\n",
    "class CrossEncoderReranker:\n",
    "    \"\"\"Reranker using HuggingFace Cross-Encoder models.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "        top_n: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"Initialize with CrossEncoder model.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.top_n = top_n\n",
    "        \n",
    "        # Load cross-encoder model\n",
    "        self.model = CrossEncoder(model_name, device=\"cpu\")\n",
    "        print(f\"Loaded CrossEncoder model: {model_name}\")\n",
    "    \n",
    "    def rerank(self, query: str, nodes: List[NodeWithScore]) -> List[NodeWithScore]:\n",
    "        \"\"\"Rerank nodes for a given query.\"\"\"\n",
    "        if not nodes:\n",
    "            return []\n",
    "        \n",
    "        # Extract texts from nodes\n",
    "        node_texts = [node.node.get_content() for node in nodes]\n",
    "        \n",
    "        # Create query-document pairs\n",
    "        query_doc_pairs = [(query, text) for text in node_texts]\n",
    "        \n",
    "        # Get scores from cross-encoder\n",
    "        rerank_scores = self.model.predict(query_doc_pairs)\n",
    "        \n",
    "        # Create new NodeWithScore objects with updated scores\n",
    "        reranked_nodes = []\n",
    "        for i, node in enumerate(nodes):\n",
    "            reranked_node = NodeWithScore(\n",
    "                node=node.node,\n",
    "                score=float(rerank_scores[i])\n",
    "            )\n",
    "            reranked_nodes.append(reranked_node)\n",
    "        \n",
    "        # Sort by new scores (descending)\n",
    "        reranked_nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "        \n",
    "        # Apply top_n filter if specified\n",
    "        if self.top_n is not None and self.top_n < len(reranked_nodes):\n",
    "            reranked_nodes = reranked_nodes[:self.top_n]\n",
    "        \n",
    "        return reranked_nodes\n",
    "\n",
    "class RerankedRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever with reranking capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_retriever: BaseRetriever,\n",
    "        reranker: CrossEncoderReranker,\n",
    "        fetch_k: int = 10,\n",
    "    ):\n",
    "        \"\"\"Initialize with base retriever and reranker.\"\"\"\n",
    "        self.base_retriever = base_retriever\n",
    "        self.reranker = reranker\n",
    "        self.fetch_k = fetch_k\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve and rerank nodes for the given query.\"\"\"\n",
    "        # Step 1: Get initial candidates from base retriever\n",
    "        base_nodes = self.base_retriever.retrieve(query_bundle)\n",
    "        \n",
    "        # Limit candidates if fetch_k is specified\n",
    "        if self.fetch_k is not None and len(base_nodes) > self.fetch_k:\n",
    "            base_nodes = base_nodes[:self.fetch_k]\n",
    "        \n",
    "        # Step 2: Rerank the candidates\n",
    "        reranked_nodes = self.reranker.rerank(\n",
    "            query=query_bundle.query_str,\n",
    "            nodes=base_nodes\n",
    "        )\n",
    "        \n",
    "        return reranked_nodes\n",
    "\n",
    "# Create cross-encoder reranker\n",
    "reranker = CrossEncoderReranker(\n",
    "    model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "# Create reranked retriever with weighted fusion as base\n",
    "reranked_retriever = RerankedRetriever(\n",
    "    base_retriever=weighted_fusion_retriever,\n",
    "    reranker=reranker,\n",
    "    fetch_k=10\n",
    ")\n",
    "print(\"\\nCreated reranked retriever\")\n",
    "\n",
    "# Test reranked retriever\n",
    "reranked_results = test_retriever(reranked_retriever, query, \"Reranked Retriever\")\n",
    "\n",
    "## 8. Complete Configurable Pipeline\n",
    "\n",
    "class RetrievalPipeline:\n",
    "    \"\"\"A configurable retrieval pipeline that combines multiple techniques.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        use_bm25: bool = True,\n",
    "        use_vector: bool = True,\n",
    "        use_hybrid: bool = True,\n",
    "        use_reranking: bool = True,\n",
    "        vector_weight: float = 0.7,\n",
    "        bm25_weight: float = 0.3,\n",
    "        top_k: int = 5,\n",
    "        rerank_top_k: int = 10\n",
    "    ):\n",
    "        \"\"\"Initialize the pipeline with configuration.\"\"\"\n",
    "        self.config = {\n",
    "            \"use_bm25\": use_bm25,\n",
    "            \"use_vector\": use_vector,\n",
    "            \"use_hybrid\": use_hybrid,\n",
    "            \"use_reranking\": use_reranking,\n",
    "            \"vector_weight\": vector_weight,\n",
    "            \"bm25_weight\": bm25_weight,\n",
    "            \"top_k\": top_k,\n",
    "            \"rerank_top_k\": rerank_top_k\n",
    "        }\n",
    "        \n",
    "        self.retrievers = {}\n",
    "        self.pipeline = None\n",
    "        print(\"Created configurable retrieval pipeline\")\n",
    "    \n",
    "    def build(self, nodes: List[TextNode]):\n",
    "        \"\"\"Build the pipeline based on the configuration and document nodes.\"\"\"\n",
    "        print(\"\\nBuilding retrieval pipeline...\")\n",
    "        \n",
    "        # Build BM25 retriever if enabled\n",
    "        if self.config[\"use_bm25\"]:\n",
    "            self.retrievers[\"bm25\"] = BM25Retriever.from_defaults(\n",
    "                nodes=nodes, \n",
    "                similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "            print(\"- Added BM25 retriever\")\n",
    "        \n",
    "        # Build vector retriever if enabled\n",
    "        if self.config[\"use_vector\"]:\n",
    "            # Set up embedding model\n",
    "            model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            embed_model = HuggingFaceEmbedding(model_name=model_name)\n",
    "            \n",
    "            # Ensure nodes have embeddings\n",
    "            bi_encoder = SentenceTransformer(model_name, device=\"cpu\")\n",
    "            for node in nodes:\n",
    "                if node.embedding is None:\n",
    "                    node.embedding = bi_encoder.encode(node.get_content())\n",
    "            \n",
    "            # Create vector index and retriever\n",
    "            vector_index = VectorStoreIndex(nodes=nodes, embed_model=embed_model)\n",
    "            self.retrievers[\"vector\"] = vector_index.as_retriever(\n",
    "                similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "            print(\"- Added vector retriever\")\n",
    "        \n",
    "        # Build hybrid retriever if enabled and we have multiple retrievers\n",
    "        base_retriever = None\n",
    "        if self.config[\"use_hybrid\"] and len(self.retrievers) > 1:\n",
    "            weights = {}\n",
    "            if \"vector\" in self.retrievers:\n",
    "                weights[\"vector\"] = self.config[\"vector_weight\"]\n",
    "            if \"bm25\" in self.retrievers:\n",
    "                weights[\"bm25\"] = self.config[\"bm25_weight\"]\n",
    "            \n",
    "            base_retriever = WeightedFusionRetriever(\n",
    "                retrievers=self.retrievers,\n",
    "                weights=weights\n",
    "            )\n",
    "            print(\"- Added weighted fusion for hybrid retrieval\")\n",
    "        else:\n",
    "            # Use the first available retriever as base\n",
    "            retriever_name = next(iter(self.retrievers.keys()))\n",
    "            base_retriever = self.retrievers[retriever_name]\n",
    "            print(f\"- Using {retriever_name} as base retriever\")\n",
    "        \n",
    "        # Build reranker if enabled\n",
    "        if self.config[\"use_reranking\"]:\n",
    "            reranker = CrossEncoderReranker(\n",
    "                model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "                top_n=self.config[\"top_k\"]\n",
    "            )\n",
    "            \n",
    "            self.pipeline = RerankedRetriever(\n",
    "                base_retriever=base_retriever,\n",
    "                reranker=reranker,\n",
    "                fetch_k=self.config[\"rerank_top_k\"]\n",
    "            )\n",
    "            print(\"- Added cross-encoder reranker\")\n",
    "        else:\n",
    "            self.pipeline = base_retriever\n",
    "        \n",
    "        print(\"Pipeline build complete!\")\n",
    "        return self\n",
    "    \n",
    "    def retrieve(self, query: Union[str, QueryBundle], verbose: bool = True):\n",
    "        \"\"\"Execute the retrieval pipeline on a query.\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Pipeline not built. Call build() first.\")\n",
    "        \n",
    "        # Convert string query to QueryBundle if needed\n",
    "        if isinstance(query, str):\n",
    "            query = QueryBundle(query)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        results = self.pipeline.retrieve(query)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n=== Retrieval Results ===\")\n",
    "            print(f\"Query: '{query.query_str}'\")\n",
    "            print(f\"Retrieved {len(results)} documents in {(end_time - start_time):.4f} seconds\")\n",
    "            \n",
    "            for i, node in enumerate(results, 1):\n",
    "                print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Create and test a complete pipeline\n",
    "complete_pipeline = RetrievalPipeline(\n",
    "    use_bm25=True,\n",
    "    use_vector=True,\n",
    "    use_hybrid=True,\n",
    "    use_reranking=True,\n",
    "    vector_weight=0.7,\n",
    "    bm25_weight=0.3,\n",
    "    top_k=5,\n",
    "    rerank_top_k=10\n",
    ").build(nodes)\n",
    "\n",
    "# Test the pipeline with a query\n",
    "pipeline_results = complete_pipeline.retrieve(\"How can Python be used for natural language processing?\")\n",
    "\n",
    "## 9. Compare Different Pipeline Configurations\n",
    "\n",
    "def compare_pipeline_configurations(nodes, query, configs):\n",
    "    \"\"\"Compare different pipeline configurations on the same query.\"\"\"\n",
    "    print(\"\\n=== Pipeline Configuration Comparison ===\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    \n",
    "    results = {}\n",
    "    for name, config in configs.items():\n",
    "        print(f\"\\nTesting configuration: {name}\")\n",
    "        \n",
    "        # Create pipeline with configuration\n",
    "        pipeline = RetrievalPipeline(**config).build(nodes)\n",
    "        \n",
    "        # Retrieve results\n",
    "        start_time = time.time()\n",
    "        retrieval_results = pipeline.retrieve(query, verbose=False)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"time\": end_time - start_time,\n",
    "            \"results\": retrieval_results\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Retrieved {len(retrieval_results)} documents in {(end_time - start_time):.4f} seconds\")\n",
    "        print(f\"Top result: {retrieval_results[0].node.get_content()[:100]}...\")\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    for name, result in results.items():\n",
    "        print(f\"{name}: {result['time']:.4f}s, {len(result['results'])} results\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define different configurations to compare\n",
    "pipeline_configs = {\n",
    "    \"BM25 Only\": {\n",
    "        \"use_bm25\": True,\n",
    "        \"use_vector\": False,\n",
    "        \"use_hybrid\": False,\n",
    "        \"use_reranking\": False\n",
    "    },\n",
    "    \"Vector Only\": {\n",
    "        \"use_bm25\": False,\n",
    "        \"use_vector\": True,\n",
    "        \"use_hybrid\": False,\n",
    "        \"use_reranking\": False\n",
    "    },\n",
    "    \"Hybrid (No Reranking)\": {\n",
    "        \"use_bm25\": True,\n",
    "        \"use_vector\": True,\n",
    "        \"use_hybrid\": True,\n",
    "        \"use_reranking\": False\n",
    "    },\n",
    "    \"Complete Pipeline\": {\n",
    "        \"use_bm25\": True,\n",
    "        \"use_vector\": True,\n",
    "        \"use_hybrid\": True,\n",
    "        \"use_reranking\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Compare different configurations\n",
    "comparison_query = \"What are transformer models used for in NLP?\"\n",
    "comparison_results = compare_pipeline_configurations(nodes, comparison_query, pipeline_configs)\n",
    "\n",
    "print(\"\\nRetrieval pipeline notebook complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 sample documents\n",
      "Created basic retrievers\n",
      "Created hybrid retriever\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Created reranked retriever\n",
      "\n",
      "=== Pipeline Configuration Comparison ===\n",
      "\n",
      "Building pipeline: use_bm25\n",
      "\n",
      "BM25 Only (0.0013s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Machine learning is a subset of AI that enables systems to learn from data.\n",
      "\n",
      "Building pipeline: use_vector\n",
      "\n",
      "Vector Only (0.0135s):\n",
      "1. Python is a high-level programming language known for its readability.\n",
      "2. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "\n",
      "Building pipeline: use_bm25, use_vector, use_hybrid\n",
      "\n",
      "Hybrid (0.0143s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Machine learning is a subset of AI that enables systems to learn from data.\n",
      "\n",
      "Building pipeline: use_bm25, use_vector, use_hybrid, use_reranking\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "\n",
      "Full Pipeline (0.0494s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Python is a high-level programming language known for its readability.\n",
      "\n",
      "Retrieval pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "# Complete Retrieval Pipeline: From Basic to Advanced\n",
    "\n",
    "# 1. Setup and Imports\n",
    "\n",
    "import time\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core.schema import Document, NodeWithScore, QueryBundle, TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Hugging Face imports\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 2. Create Sample Documents\n",
    "\n",
    "# Create a set of sample documents\n",
    "texts = [\n",
    "    \"Python is a high-level programming language known for its readability.\",\n",
    "    \"Machine learning is a subset of AI that enables systems to learn from data.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks.\",\n",
    "    \"Deep learning uses neural networks with many layers to extract features from data.\",\n",
    "    \"Natural language processing helps computers understand human language.\",\n",
    "    \"Python libraries like PyTorch and TensorFlow are used for deep learning.\",\n",
    "    \"BM25 is a bag-of-words retrieval function used in information retrieval.\",\n",
    "    \"Vector search finds documents by measuring similarity in embedding space.\",\n",
    "    \"Reranking refines initial search results with a more complex model.\",\n",
    "    \"Retrieval pipelines combine multiple techniques for better search results.\"\n",
    "]\n",
    "\n",
    "# Convert to documents and nodes\n",
    "documents = [Document(text=text, id_=f\"doc_{i}\")\n",
    "             for i, text in enumerate(texts)]\n",
    "nodes = [TextNode(text=doc.text, id_=doc.id_) for doc in documents]\n",
    "print(f\"Created {len(documents)} sample documents\")\n",
    "\n",
    "# 3. Test Function\n",
    "\n",
    "\n",
    "def test_retriever(retriever, query_text, name=\"Retriever\"):\n",
    "    \"\"\"Test a retriever with a query and print results.\"\"\"\n",
    "    print(f\"\\n=== Testing {name} ===\")\n",
    "    start_time = time.time()\n",
    "    results = retriever.retrieve(QueryBundle(query_text))\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(\n",
    "        f\"Retrieved {len(results)} documents in {(end_time - start_time):.4f} seconds\")\n",
    "\n",
    "    for i, node in enumerate(results[:3], 1):  # Show just top 3 for brevity\n",
    "        print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# 4. Basic Retrievers\n",
    "\n",
    "\n",
    "# Set up BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=5)\n",
    "\n",
    "# Set up vector retriever\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bi_encoder = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "# Create embeddings for nodes\n",
    "for node in nodes:\n",
    "    node.embedding = bi_encoder.encode(node.get_content())\n",
    "\n",
    "# Create vector index and retriever\n",
    "vector_index = VectorStoreIndex(\n",
    "    nodes=nodes, embed_model=HuggingFaceEmbedding(model_name=model_name))\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "print(\"Created basic retrievers\")\n",
    "\n",
    "# 5. Hybrid Retriever\n",
    "\n",
    "\n",
    "class WeightedFusionRetriever(BaseRetriever):\n",
    "    \"\"\"Weighted fusion retriever that combines results from multiple retrievers.\"\"\"\n",
    "\n",
    "    def __init__(self, retrievers: Dict[str, BaseRetriever], weights: Dict[str, float]):\n",
    "        \"\"\"Initialize with retrievers and weights.\"\"\"\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        all_results = {}\n",
    "\n",
    "        for name, retriever in self.retrievers.items():\n",
    "            results = retriever.retrieve(query_bundle)\n",
    "            weight = self.weights.get(name, 1.0)\n",
    "\n",
    "            for node_with_score in results:\n",
    "                node_id = node_with_score.node.node_id\n",
    "                weighted_score = node_with_score.score * weight\n",
    "\n",
    "                if node_id not in all_results:\n",
    "                    all_results[node_id] = {\n",
    "                        \"node\": node_with_score.node,\n",
    "                        \"scores\": {}\n",
    "                    }\n",
    "                all_results[node_id][\"scores\"][name] = weighted_score\n",
    "\n",
    "        final_results = []\n",
    "        for node_id, data in all_results.items():\n",
    "            final_results.append(NodeWithScore(\n",
    "                node=data[\"node\"],\n",
    "                score=sum(data[\"scores\"].values())\n",
    "            ))\n",
    "\n",
    "        return sorted(final_results, key=lambda x: x.score, reverse=True)\n",
    "\n",
    "\n",
    "# Create weighted fusion retriever\n",
    "hybrid_retriever = WeightedFusionRetriever(\n",
    "    retrievers={\"vector\": vector_retriever, \"bm25\": bm25_retriever},\n",
    "    weights={\"vector\": 0.7, \"bm25\": 0.3}\n",
    ")\n",
    "print(\"Created hybrid retriever\")\n",
    "\n",
    "# 6. Reranker\n",
    "\n",
    "\n",
    "class CrossEncoderReranker:\n",
    "    \"\"\"Reranker using HuggingFace Cross-Encoder models.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\", top_n=None):\n",
    "        self.model = CrossEncoder(model_name, device=\"cpu\")\n",
    "        self.top_n = top_n\n",
    "        print(f\"Loaded CrossEncoder model: {model_name}\")\n",
    "\n",
    "    def rerank(self, query: str, nodes: List[NodeWithScore]) -> List[NodeWithScore]:\n",
    "        if not nodes:\n",
    "            return []\n",
    "\n",
    "        # Create query-document pairs and get scores\n",
    "        node_texts = [node.node.get_content() for node in nodes]\n",
    "        query_doc_pairs = [(query, text) for text in node_texts]\n",
    "        rerank_scores = self.model.predict(query_doc_pairs)\n",
    "\n",
    "        # Create reranked nodes\n",
    "        reranked_nodes = [\n",
    "            NodeWithScore(node=node.node, score=float(score))\n",
    "            for node, score in zip(nodes, rerank_scores)\n",
    "        ]\n",
    "\n",
    "        # Sort and filter\n",
    "        reranked_nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "        if self.top_n is not None:\n",
    "            reranked_nodes = reranked_nodes[:self.top_n]\n",
    "\n",
    "        return reranked_nodes\n",
    "\n",
    "\n",
    "class RerankedRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever with reranking capabilities.\"\"\"\n",
    "\n",
    "    def __init__(self, base_retriever, reranker, fetch_k=10):\n",
    "        self.base_retriever = base_retriever\n",
    "        self.reranker = reranker\n",
    "        self.fetch_k = fetch_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        # Get initial candidates\n",
    "        base_nodes = self.base_retriever.retrieve(query_bundle)\n",
    "        if self.fetch_k is not None:\n",
    "            base_nodes = base_nodes[:self.fetch_k]\n",
    "\n",
    "        # Rerank candidates\n",
    "        return self.reranker.rerank(query_bundle.query_str, base_nodes)\n",
    "\n",
    "\n",
    "# Create reranked retriever\n",
    "reranker = CrossEncoderReranker(top_n=5)\n",
    "reranked_retriever = RerankedRetriever(\n",
    "    base_retriever=hybrid_retriever, reranker=reranker)\n",
    "print(\"Created reranked retriever\")\n",
    "\n",
    "# 7. Complete Pipeline\n",
    "\n",
    "\n",
    "class RetrievalPipeline:\n",
    "    \"\"\"A configurable retrieval pipeline.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_bm25=True,\n",
    "        use_vector=True,\n",
    "        use_hybrid=True,\n",
    "        use_reranking=True,\n",
    "        vector_weight=0.7,\n",
    "        bm25_weight=0.3,\n",
    "        top_k=5,\n",
    "        rerank_top_k=10\n",
    "    ):\n",
    "        self.config = {\n",
    "            \"use_bm25\": use_bm25, \"use_vector\": use_vector,\n",
    "            \"use_hybrid\": use_hybrid, \"use_reranking\": use_reranking,\n",
    "            \"vector_weight\": vector_weight, \"bm25_weight\": bm25_weight,\n",
    "            \"top_k\": top_k, \"rerank_top_k\": rerank_top_k\n",
    "        }\n",
    "        self.pipeline = None\n",
    "\n",
    "    def build(self, nodes):\n",
    "        \"\"\"Build the pipeline based on configuration.\"\"\"\n",
    "        print(\n",
    "            f\"\\nBuilding pipeline: {', '.join(k for k, v in self.config.items() if v and k.startswith('use_'))}\")\n",
    "\n",
    "        # Initialize retrievers\n",
    "        retrievers = {}\n",
    "        if self.config[\"use_bm25\"]:\n",
    "            retrievers[\"bm25\"] = BM25Retriever.from_defaults(\n",
    "                nodes=nodes, similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "\n",
    "        if self.config[\"use_vector\"]:\n",
    "            # Ensure nodes have embeddings\n",
    "            model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            embed_model = HuggingFaceEmbedding(model_name=model_name)\n",
    "            bi_encoder = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "            for node in nodes:\n",
    "                if node.embedding is None:\n",
    "                    node.embedding = bi_encoder.encode(node.get_content())\n",
    "\n",
    "            vector_index = VectorStoreIndex(\n",
    "                nodes=nodes, embed_model=embed_model)\n",
    "            retrievers[\"vector\"] = vector_index.as_retriever(\n",
    "                similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "\n",
    "        # Build base retriever\n",
    "        if self.config[\"use_hybrid\"] and len(retrievers) > 1:\n",
    "            weights = {}\n",
    "            if \"vector\" in retrievers:\n",
    "                weights[\"vector\"] = self.config[\"vector_weight\"]\n",
    "            if \"bm25\" in retrievers:\n",
    "                weights[\"bm25\"] = self.config[\"bm25_weight\"]\n",
    "\n",
    "            base_retriever = WeightedFusionRetriever(\n",
    "                retrievers=retrievers, weights=weights)\n",
    "        else:\n",
    "            # Use the first available retriever\n",
    "            retriever_name = next(iter(retrievers.keys()))\n",
    "            base_retriever = retrievers[retriever_name]\n",
    "\n",
    "        # Add reranker if enabled\n",
    "        if self.config[\"use_reranking\"]:\n",
    "            reranker = CrossEncoderReranker(top_n=self.config[\"top_k\"])\n",
    "            self.pipeline = RerankedRetriever(\n",
    "                base_retriever=base_retriever,\n",
    "                reranker=reranker,\n",
    "                fetch_k=self.config[\"rerank_top_k\"]\n",
    "            )\n",
    "        else:\n",
    "            self.pipeline = base_retriever\n",
    "\n",
    "        return self\n",
    "\n",
    "    def retrieve(self, query, verbose=True):\n",
    "        \"\"\"Execute the retrieval pipeline.\"\"\"\n",
    "        if isinstance(query, str):\n",
    "            query = QueryBundle(query)\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = self.pipeline.retrieve(query)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Results ({elapsed:.4f}s) ===\")\n",
    "            for i, node in enumerate(results[:3], 1):\n",
    "                print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "# 8. Compare Configurations\n",
    "\n",
    "\n",
    "# Define different configurations\n",
    "configurations = {\n",
    "    \"BM25 Only\": {\"use_bm25\": True, \"use_vector\": False, \"use_hybrid\": False, \"use_reranking\": False},\n",
    "    \"Vector Only\": {\"use_bm25\": False, \"use_vector\": True, \"use_hybrid\": False, \"use_reranking\": False},\n",
    "    \"Hybrid\": {\"use_bm25\": True, \"use_vector\": True, \"use_hybrid\": True, \"use_reranking\": False},\n",
    "    \"Full Pipeline\": {\"use_bm25\": True, \"use_vector\": True, \"use_hybrid\": True, \"use_reranking\": True}\n",
    "}\n",
    "\n",
    "# Test query\n",
    "query = \"How is Python used in machine learning?\"\n",
    "\n",
    "# Test each pipeline configuration\n",
    "print(\"\\n=== Pipeline Configuration Comparison ===\")\n",
    "for name, config in configurations.items():\n",
    "    pipeline = RetrievalPipeline(**config).build(nodes)\n",
    "    start = time.time()\n",
    "    results = pipeline.retrieve(query, verbose=False)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"\\n{name} ({elapsed:.4f}s):\")\n",
    "    for i, node in enumerate(results[:2], 1):\n",
    "        print(f\"{i}. {node.node.get_content()}\")\n",
    "\n",
    "print(\"\\nRetrieval pipeline complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core.schema import Document, NodeWithScore, QueryBundle, TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 sample documents\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Python is a high-level programming language known for its readability.\",\n",
    "    \"Machine learning is a subset of AI that enables systems to learn from data.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks.\",\n",
    "    \"Deep learning uses neural networks with many layers to extract features from data.\",\n",
    "    \"Natural language processing helps computers understand human language.\",\n",
    "    \"Python libraries like PyTorch and TensorFlow are used for deep learning.\",\n",
    "    \"BM25 is a bag-of-words retrieval function used in information retrieval.\",\n",
    "    \"Vector search finds documents by measuring similarity in embedding space.\",\n",
    "    \"Reranking refines initial search results with a more complex model.\",\n",
    "    \"Retrieval pipelines combine multiple techniques for better search results.\"\n",
    "]\n",
    "\n",
    "documents = [Document(text=text, id_=f\"doc_{i}\")\n",
    "             for i, text in enumerate(texts)]\n",
    "nodes = [TextNode(text=doc.text, id_=doc.id_) for doc in documents]\n",
    "print(f\"Created {len(documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2299ce94da4ae8b68573c828d9ac2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ca847409ea4b949a38c66545ba4a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0810fa51d13478da43c99c61cfbb01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d61dc3db6fd4e1584291068b69fcf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e6320faf9c4d8bb7dac1900c6666dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405d5e9a8a2b48a580ecaefeb580e200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cd97620f8e44eb86576eb5f59d857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d652097c933a4b69a0e886c151d6b65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3917fc6883410d87fb56623ac6ce85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa6b1d6215b4642933eed4a316ff733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592ea8ff88a440b18f09b5a4379a32af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created basic retrievers\n"
     ]
    }
   ],
   "source": [
    "# Set Up Basic Retrievers\n",
    "\n",
    "# BM25 retriever for lexical search\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=5)\n",
    "\n",
    "# Vector retriever for semantic search\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_index = VectorStoreIndex(nodes=nodes, embed_model=embed_model)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "print(\"Created basic retrievers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created hybrid retriever\n"
     ]
    }
   ],
   "source": [
    "#  Create Hybrid Retriever\n",
    "class WeightedFusionRetriever(BaseRetriever):\n",
    "    \"\"\"Combines results from multiple retrievers with weights.\"\"\"\n",
    "\n",
    "    def __init__(self, retrievers: Dict[str, BaseRetriever], weights: Dict[str, float]):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        all_results = {}\n",
    "\n",
    "        # Get results from each retriever\n",
    "        for name, retriever in self.retrievers.items():\n",
    "            results = retriever.retrieve(query_bundle)\n",
    "            weight = self.weights.get(name, 1.0)\n",
    "\n",
    "            # Combine results with weighting\n",
    "            for node in results:\n",
    "                node_id = node.node.node_id\n",
    "                weighted_score = node.score * weight\n",
    "\n",
    "                if node_id not in all_results:\n",
    "                    all_results[node_id] = {\"node\": node.node, \"scores\": {}}\n",
    "                all_results[node_id][\"scores\"][name] = weighted_score\n",
    "\n",
    "        # Create final results with combined scores\n",
    "        final_results = [\n",
    "            NodeWithScore(node=data[\"node\"], score=sum(\n",
    "                data[\"scores\"].values()))\n",
    "            for node_id, data in all_results.items()\n",
    "        ]\n",
    "\n",
    "        return sorted(final_results, key=lambda x: x.score, reverse=True)\n",
    "\n",
    "\n",
    "# Create hybrid retriever\n",
    "hybrid_retriever = WeightedFusionRetriever(\n",
    "    retrievers={\"vector\": vector_retriever, \"bm25\": bm25_retriever},\n",
    "    weights={\"vector\": 0.7, \"bm25\": 0.3}\n",
    ")\n",
    "print(\"Created hybrid retriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    }
   ],
   "source": [
    "# Add Reranking\n",
    "\n",
    "class RerankedRetriever(BaseRetriever):\n",
    "    \"\"\"Two-stage retriever: initial retrieval + cross-encoder reranking.\"\"\"\n",
    "\n",
    "    def __init__(self, base_retriever, model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "                 fetch_k=10, top_k=5):\n",
    "        self.base_retriever = base_retriever\n",
    "        self.reranker = CrossEncoder(model_name, device=\"cpu\")\n",
    "        self.fetch_k = fetch_k\n",
    "        self.top_k = top_k\n",
    "        super().__init__()\n",
    "        print(f\"Loaded CrossEncoder model: {model_name}\")\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        # Stage 1: Get initial candidates from base retriever\n",
    "        base_nodes = self.base_retriever.retrieve(query_bundle)[:self.fetch_k]\n",
    "\n",
    "        # Early return if no results\n",
    "        if not base_nodes:\n",
    "            return []\n",
    "\n",
    "        # Stage 2: Rerank candidates with cross-encoder\n",
    "        query = query_bundle.query_str\n",
    "        node_texts = [node.node.get_content() for node in base_nodes]\n",
    "        rerank_scores = self.reranker.predict(\n",
    "            [(query, text) for text in node_texts])\n",
    "\n",
    "        # Create reranked nodes\n",
    "        reranked_nodes = [\n",
    "            NodeWithScore(node=node.node, score=float(score))\n",
    "            for node, score in zip(base_nodes, rerank_scores)\n",
    "        ]\n",
    "\n",
    "        # Sort and filter\n",
    "        reranked_nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "        return reranked_nodes[:self.top_k] if self.top_k else reranked_nodes\n",
    "\n",
    "\n",
    "# Create reranked retriever\n",
    "reranked_retriever = RerankedRetriever(\n",
    "    base_retriever=hybrid_retriever,\n",
    "    fetch_k=10,\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Complete Pipeline\n",
    "\n",
    "class RetrievalPipeline:\n",
    "    \"\"\"Configurable retrieval pipeline combining multiple techniques.\"\"\"\n",
    "\n",
    "    def __init__(self, use_bm25=True, use_vector=True, use_hybrid=True, use_reranking=True,\n",
    "                 vector_weight=0.7, bm25_weight=0.3, top_k=5, rerank_top_k=10):\n",
    "        self.config = {\n",
    "            \"use_bm25\": use_bm25, \"use_vector\": use_vector,\n",
    "            \"use_hybrid\": use_hybrid, \"use_reranking\": use_reranking,\n",
    "            \"vector_weight\": vector_weight, \"bm25_weight\": bm25_weight,\n",
    "            \"top_k\": top_k, \"rerank_top_k\": rerank_top_k\n",
    "        }\n",
    "        self.pipeline = None\n",
    "\n",
    "    def build(self, nodes):\n",
    "        \"\"\"Build the pipeline based on configuration.\"\"\"\n",
    "        enabled = [k for k, v in self.config.items()\n",
    "                   if v and k.startswith('use_')]\n",
    "        print(f\"\\nBuilding pipeline: {', '.join(enabled)}\")\n",
    "\n",
    "        # Set up retrievers\n",
    "        retrievers = {}\n",
    "        if self.config[\"use_bm25\"]:\n",
    "            retrievers[\"bm25\"] = BM25Retriever.from_defaults(\n",
    "                nodes=nodes, similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "\n",
    "        if self.config[\"use_vector\"]:\n",
    "            embed_model = HuggingFaceEmbedding(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            )\n",
    "            vector_index = VectorStoreIndex(\n",
    "                nodes=nodes, embed_model=embed_model)\n",
    "            retrievers[\"vector\"] = vector_index.as_retriever(\n",
    "                similarity_top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "\n",
    "        # Select base retriever\n",
    "        if self.config[\"use_hybrid\"] and len(retrievers) > 1:\n",
    "            weights = {\n",
    "                \"vector\": self.config[\"vector_weight\"],\n",
    "                \"bm25\": self.config[\"bm25_weight\"]\n",
    "            }\n",
    "            base_retriever = WeightedFusionRetriever(\n",
    "                retrievers=retrievers, weights=weights)\n",
    "        else:\n",
    "            retriever_name = next(iter(retrievers.keys()))\n",
    "            base_retriever = retrievers[retriever_name]\n",
    "\n",
    "        # Add reranking if enabled\n",
    "        if self.config[\"use_reranking\"]:\n",
    "            self.pipeline = RerankedRetriever(\n",
    "                base_retriever=base_retriever,\n",
    "                fetch_k=self.config[\"rerank_top_k\"],\n",
    "                top_k=self.config[\"top_k\"]\n",
    "            )\n",
    "        else:\n",
    "            self.pipeline = base_retriever\n",
    "\n",
    "        return self\n",
    "\n",
    "    def retrieve(self, query, verbose=True):\n",
    "        \"\"\"Execute the retrieval pipeline on a query.\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Pipeline not built. Call build() first.\")\n",
    "\n",
    "        if isinstance(query, str):\n",
    "            query = QueryBundle(query)\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = self.pipeline.retrieve(query)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Results ({elapsed:.4f}s) ===\")\n",
    "            for i, node in enumerate(results[:3], 1):\n",
    "                print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pipeline Configuration Comparison ===\n",
      "Query: 'How is Python used in machine learning?'\n",
      "\n",
      "Building pipeline: use_bm25\n",
      "\n",
      "BM25 Only (0.0024s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Machine learning is a subset of AI that enables systems to learn from data.\n",
      "\n",
      "Building pipeline: use_vector\n",
      "\n",
      "Vector Only (0.0154s):\n",
      "1. Python is a high-level programming language known for its readability.\n",
      "2. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "\n",
      "Building pipeline: use_bm25, use_vector, use_hybrid\n",
      "\n",
      "Hybrid (0.0145s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Machine learning is a subset of AI that enables systems to learn from data.\n",
      "\n",
      "Building pipeline: use_bm25, use_vector, use_hybrid, use_reranking\n",
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "\n",
      "Full Pipeline (0.1995s):\n",
      "1. Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Python is a high-level programming language known for its readability.\n",
      "\n",
      "Retrieval pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "def test_configurations(nodes, query):\n",
    "    \"\"\"Compare different pipeline configurations on the same query.\"\"\"\n",
    "    configurations = {\n",
    "        \"BM25 Only\": {\"use_bm25\": True, \"use_vector\": False, \"use_hybrid\": False, \"use_reranking\": False},\n",
    "        \"Vector Only\": {\"use_bm25\": False, \"use_vector\": True, \"use_hybrid\": False, \"use_reranking\": False},\n",
    "        \"Hybrid\": {\"use_bm25\": True, \"use_vector\": True, \"use_hybrid\": True, \"use_reranking\": False},\n",
    "        \"Full Pipeline\": {\"use_bm25\": True, \"use_vector\": True, \"use_hybrid\": True, \"use_reranking\": True}\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== Pipeline Configuration Comparison ===\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "\n",
    "    for name, config in configurations.items():\n",
    "        pipeline = RetrievalPipeline(**config).build(nodes)\n",
    "        start = time.time()\n",
    "        results = pipeline.retrieve(query, verbose=False)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"\\n{name} ({elapsed:.4f}s):\")\n",
    "        for i, node in enumerate(results[:2], 1):\n",
    "            print(f\"{i}. {node.node.get_content()}\")\n",
    "\n",
    "\n",
    "# Run the comparison\n",
    "test_configurations(nodes, \"How is Python used in machine learning?\")\n",
    "print(\"\\nRetrieval pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Considerations \n",
    "\n",
    "1. Performance Optimization:\n",
    "    - Pre-compute and cache embeddings\n",
    "    - Consider using approximate nearest neighbor (ANN) indexes for vector search at scale\n",
    "    - Adjust fetch_k and top_k based on your application's latency requirements\n",
    "\n",
    "2. Model Selection:\n",
    "    - Choose embedding models based on your domain\n",
    "    - Test different cross-encoder models for quality\n",
    "    - Consider distilled models for better speed\n",
    "\n",
    "3. Resource Allocation:\n",
    "    - BM25 is CPU-bound and memory-efficient\n",
    "    - Vector search benefits from GPU acceleration\n",
    "    - Cross-encoders are more resource-intensive\n",
    "\n",
    "4. Observability:\n",
    "    - Log timing information for each stage\n",
    "    - Track retrieval quality metrics\n",
    "    - Monitor model performance over time\n",
    "\n",
    "4. Adaptive Configuration:\n",
    "    - Consider adjusting weights based on query type\n",
    "    - Use different pipelines for different use cases\n",
    "    - A/B test configuration changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
