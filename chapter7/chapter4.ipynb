{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Retrieval with Reranking\n",
    "\n",
    "Reranking is a two-stage process:\n",
    "\n",
    "1. Initial Retrieval: First, we use our existing retrievers (like BM25, vector search, or hybrid approaches) to efficiently fetch a candidate set of potentially relevant documents.\n",
    "2. Reranking: Then, we apply a more computationally intensive model to score and reorder these candidates based on their relevance to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Encoders vs. Bi-Encoders:\n",
    "\n",
    "- Bi-Encoders (like those used in vector search):\n",
    "    - Encode queries and documents separately\n",
    "    - Allow for pre-computation of document embeddings\n",
    "    - Efficient for initial retrieval across large collections\n",
    "    - Examples: OpenAI embeddings, sentence-transformers, etc.\n",
    "\n",
    "- Cross-Encoders:\n",
    "    - Process query and document pairs together\n",
    "    - Capture complex interactions between query and document\n",
    "    - More accurate at assessing relevance\n",
    "    - Computationally more expensive (can't pre-compute)\n",
    "    - Examples: BERT-based cross-encoders from Hugging Face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, QueryBundle, Document, TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# Hugging Face imports\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "# For demonstration\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    \"\"\"BiEncoder using Sentence Transformers for initial retrieval.\n",
    "    \n",
    "    Bi-encoders encode queries and documents separately, allowing\n",
    "    for efficient retrieval from large collections by pre-computing \n",
    "    document embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    ):\n",
    "        \"\"\"Initialize with SentenceTransformer model.\"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # Load bi-encoder model (CPU for Codespaces)\n",
    "        self.model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "        print(f\"Loaded BiEncoder model: {model_name}\")\n",
    "\n",
    "    def encode(self, texts):\n",
    "        \"\"\"Encode texts to embedding vectors.\"\"\"\n",
    "        return self.model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderReranker:\n",
    "    \"\"\"Reranker using HuggingFace Cross-Encoder models.\n",
    "    \n",
    "    Cross-encoders process query-document pairs together to capture\n",
    "    complex interactions, providing more accurate relevance scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "        top_n: int = None,\n",
    "    ):\n",
    "        \"\"\"Initialize with CrossEncoder model.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.top_n = top_n\n",
    "\n",
    "        # Load cross-encoder model (always use CPU for Codespaces)\n",
    "        self.model = CrossEncoder(model_name, device=\"cpu\")\n",
    "        print(f\"Loaded CrossEncoder model: {model_name}\")\n",
    "\n",
    "    def rerank(\n",
    "        self,\n",
    "        query: str,\n",
    "        nodes: List[NodeWithScore]\n",
    "    ) -> List[NodeWithScore]:\n",
    "        \"\"\"Rerank nodes for a given query.\"\"\"\n",
    "        if not nodes:\n",
    "            return []\n",
    "\n",
    "        # Extract texts from nodes\n",
    "        node_texts = [node.node.get_content() for node in nodes]\n",
    "\n",
    "        # Create query-document pairs\n",
    "        query_doc_pairs = [(query, text) for text in node_texts]\n",
    "\n",
    "        # Get scores from cross-encoder\n",
    "        rerank_scores = self.model.predict(query_doc_pairs)\n",
    "\n",
    "        # Create new NodeWithScore objects with updated scores\n",
    "        reranked_nodes = []\n",
    "        for i, node in enumerate(nodes):\n",
    "            reranked_node = NodeWithScore(\n",
    "                node=node.node,\n",
    "                score=float(rerank_scores[i])\n",
    "            )\n",
    "            reranked_nodes.append(reranked_node)\n",
    "\n",
    "        # Sort by new scores (descending)\n",
    "        reranked_nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "\n",
    "        # Apply top_n filter if specified\n",
    "        if self.top_n is not None and self.top_n < len(reranked_nodes):\n",
    "            reranked_nodes = reranked_nodes[:self.top_n]\n",
    "\n",
    "        return reranked_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RerankedRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever with reranking capabilities.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_retriever: BaseRetriever,\n",
    "        reranker: CrossEncoderReranker,\n",
    "        fetch_k: int = 20,\n",
    "    ):\n",
    "        \"\"\"Initialize with base retriever and reranker.\"\"\"\n",
    "        self.base_retriever = base_retriever\n",
    "        self.reranker = reranker\n",
    "        self.fetch_k = fetch_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve and rerank nodes for the given query.\"\"\"\n",
    "        # Step 1: Get initial candidates from base retriever\n",
    "        base_nodes = self.base_retriever.retrieve(query_bundle)\n",
    "\n",
    "        # Limit candidates if fetch_k is specified\n",
    "        if self.fetch_k is not None and len(base_nodes) > self.fetch_k:\n",
    "            base_nodes = base_nodes[:self.fetch_k]\n",
    "\n",
    "        # Step 2: Rerank the candidates\n",
    "        reranked_nodes = self.reranker.rerank(\n",
    "            query=query_bundle.query_str,\n",
    "            nodes=base_nodes\n",
    "        )\n",
    "\n",
    "        return reranked_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_documents():\n",
    "    \"\"\"Create a set of sample documents for demonstration.\"\"\"\n",
    "    texts = [\n",
    "        \"Python is a high-level, interpreted programming language known for its readability.\",\n",
    "        \"Machine learning is a subset of artificial intelligence that learns from data.\",\n",
    "        \"Neural networks are computing systems inspired by biological neural networks.\",\n",
    "        \"Deep learning uses neural networks with many layers to extract features from data.\",\n",
    "        \"Natural language processing helps computers understand human language.\",\n",
    "        \"Python libraries like PyTorch and TensorFlow are used for deep learning.\",\n",
    "        \"BM25 is a bag-of-words retrieval function used in information retrieval.\",\n",
    "        \"Vector search finds documents by measuring similarity in embedding space.\",\n",
    "        \"Reranking refines initial search results with a more complex model.\",\n",
    "        \"Hybrid search combines multiple retrieval methods to improve search quality.\"\n",
    "    ]\n",
    "\n",
    "    documents = []\n",
    "    for i, text in enumerate(texts):\n",
    "        doc = Document(text=text, id_=f\"doc_{i}\")\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d93be746834016970eafc8aa196c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e586d6633f41ad87424973a4bb497a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11223d03800645708a76722620df17f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601dc0252aa74894b2dd57ef862b57d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f524b3db8ba04697afaaa574ab39d0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2772399e8c6249eb8e91f2827eb11732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848f5fe0c396490bbc600cedbe4e13c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f8ce0fc5904acc9c9e6fe6897f8070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60340c4aee454a4399351dfd7339b05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d7fd8d68ef4f00983de0e38ecc37ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7c66d75db44c29b410204bb5387c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CrossEncoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Demo of reranking with a simple example.\"\"\"\n",
    "\n",
    "# Create sample documents\n",
    "documents = create_sample_documents()\n",
    "\n",
    "# Create nodes from documents\n",
    "nodes = [TextNode(text=doc.text, id_=doc.id_) for doc in documents]\n",
    "\n",
    "# Set up bi-encoder for vector search\n",
    "# This explicitly shows the bi-encoder component and configures LlamaIndex to use it\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bi_encoder = SentenceTransformer(model_name, device=\"cpu\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=model_name)\n",
    "\n",
    "# Create nodes with embeddings from our model\n",
    "# We'll compute embeddings manually to ensure SentenceTransformer is used\n",
    "for node in nodes:\n",
    "    text = node.get_content()\n",
    "    embedding = bi_encoder.encode(text)\n",
    "    node.embedding = embedding\n",
    "\n",
    "# Create vector index with our pre-embedded nodes\n",
    "vector_index = VectorStoreIndex(nodes=nodes, embed_model=embed_model)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Set up BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes, similarity_top_k=5)\n",
    "\n",
    "# Create hybrid retriever (same as from Video 3)\n",
    "class WeightedFusionRetriever(BaseRetriever):\n",
    "    def __init__(self, retrievers, weights):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle):\n",
    "        all_results = {}\n",
    "        for name, retriever in self.retrievers.items():\n",
    "            results = retriever.retrieve(query_bundle)\n",
    "            weight = self.weights.get(name, 1.0)\n",
    "\n",
    "            for node_with_score in results:\n",
    "                node_id = node_with_score.node.node_id\n",
    "                weighted_score = node_with_score.score * weight\n",
    "\n",
    "                if node_id not in all_results:\n",
    "                    all_results[node_id] = {\n",
    "                        \"node\": node_with_score.node,\n",
    "                        \"scores\": {}\n",
    "                    }\n",
    "                all_results[node_id][\"scores\"][name] = weighted_score\n",
    "\n",
    "        final_results = []\n",
    "        for node_id, data in all_results.items():\n",
    "            combined_score = sum(data[\"scores\"].values())\n",
    "            node_with_score = NodeWithScore(\n",
    "                node=data[\"node\"],\n",
    "                score=combined_score\n",
    "            )\n",
    "            final_results.append(node_with_score)\n",
    "\n",
    "        final_results.sort(key=lambda x: x.score, reverse=True)\n",
    "        return final_results\n",
    "\n",
    "# Create weighted fusion retriever\n",
    "hybrid_retriever = WeightedFusionRetriever(\n",
    "    retrievers={\"vector\": vector_retriever, \"bm25\": bm25_retriever},\n",
    "    weights={\"vector\": 0.7, \"bm25\": 0.3}\n",
    ")\n",
    "\n",
    "# Create cross-encoder reranker\n",
    "reranker = CrossEncoderReranker(\n",
    "    model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "    top_n=3\n",
    ")\n",
    "\n",
    "# Create reranked retriever\n",
    "reranked_retriever = RerankedRetriever(\n",
    "    base_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    fetch_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. EMBEDDING SIMILARITY (BI-ENCODER)\n",
      "-----------------------------------\n",
      "Bi-encoders encode queries and documents separately.\n",
      "Query: 'How is Python used in machine learning?'\n",
      "Query embedding dimensions: 384\n",
      "Document embedding dimensions: 384\n",
      "Similarity score: 0.6004\n",
      "This score was calculated without the query and document seeing each other.\n"
     ]
    }
   ],
   "source": [
    "# Show how bi-encoder works\n",
    "print(\"1. EMBEDDING SIMILARITY (BI-ENCODER)\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Bi-encoders encode queries and documents separately.\")\n",
    "\n",
    "# Define our query\n",
    "query = \"How is Python used in machine learning?\"\n",
    "\n",
    "# Encode query and a document\n",
    "query_embedding = bi_encoder.encode(query)\n",
    "doc_embedding = bi_encoder.encode(\n",
    "    \"Python libraries like PyTorch and TensorFlow are used for deep learning.\")\n",
    "\n",
    "# Calculate similarity (dot product normalized)\n",
    "# Normalize embeddings for proper cosine similarity\n",
    "query_norm = np.linalg.norm(query_embedding)\n",
    "doc_norm = np.linalg.norm(doc_embedding)\n",
    "similarity = np.dot(query_embedding, doc_embedding) / (query_norm * doc_norm)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"Query embedding dimensions: {len(query_embedding)}\")\n",
    "print(f\"Document embedding dimensions: {len(doc_embedding)}\")\n",
    "print(f\"Similarity score: {similarity:.4f}\")\n",
    "print(\"This score was calculated without the query and document seeing each other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. HYBRID RETRIEVAL RESULTS\n",
      "-------------------------\n",
      "1. Score: 0.8852 - Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Score: 0.8512 - Machine learning is a subset of artificial intelligence that learns from data.\n",
      "3. Score: 0.6068 - Python is a high-level, interpreted programming language known for its readability.\n",
      "4. Score: 0.5325 - Deep learning uses neural networks with many layers to extract features from data.\n",
      "5. Score: 0.2845 - Natural language processing helps computers understand human language.\n",
      "6. Score: 0.1412 - BM25 is a bag-of-words retrieval function used in information retrieval.\n",
      "Time: 0.0367s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. HYBRID RETRIEVAL RESULTS\")\n",
    "print(\"-------------------------\")\n",
    "hybrid_start = time.time()\n",
    "hybrid_results = hybrid_retriever.retrieve(QueryBundle(query))\n",
    "hybrid_time = time.time() - hybrid_start\n",
    "\n",
    "for i, node in enumerate(hybrid_results, 1):\n",
    "    print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "\n",
    "print(f\"Time: {hybrid_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. CROSS-ENCODER RERANKING\n",
      "-------------------------\n",
      "Cross-encoders process query and document pairs together to better capture relevance.\n",
      "1. Score: 5.1547 - Python libraries like PyTorch and TensorFlow are used for deep learning.\n",
      "2. Score: 0.4332 - Python is a high-level, interpreted programming language known for its readability.\n",
      "3. Score: -2.5431 - Machine learning is a subset of artificial intelligence that learns from data.\n",
      "Time: 1.3182s\n",
      "Reranking Overhead: 1.2816s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. CROSS-ENCODER RERANKING\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Cross-encoders process query and document pairs together to better capture relevance.\")\n",
    "rerank_start = time.time()\n",
    "reranked_results = reranked_retriever.retrieve(QueryBundle(query))\n",
    "rerank_time = time.time() - rerank_start\n",
    "\n",
    "for i, node in enumerate(reranked_results, 1):\n",
    "    print(f\"{i}. Score: {node.score:.4f} - {node.node.get_content()}\")\n",
    "\n",
    "print(f\"Time: {rerank_time:.4f}s\")\n",
    "print(f\"Reranking Overhead: {rerank_time - hybrid_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. DIRECT CROSS-ENCODER VS BI-ENCODER COMPARISON\n",
      "----------------------------------------------\n",
      "Cross-encoder score: 5.1547 (evaluates query-document pair together)\n",
      "Bi-encoder similarity: 0.6004 (compares separate embeddings)\n",
      "The cross-encoder can capture more complex relevance patterns between query and document.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. DIRECT CROSS-ENCODER VS BI-ENCODER COMPARISON\")\n",
    "print(\"----------------------------------------------\")\n",
    "test_doc = \"Python libraries like PyTorch and TensorFlow are used for deep learning.\"\n",
    "\n",
    "# Cross-encoder score\n",
    "cross_scores = reranker.model.predict([(query, test_doc)])\n",
    "print(\n",
    "    f\"Cross-encoder score: {cross_scores[0]:.4f} (evaluates query-document pair together)\")\n",
    "\n",
    "# Bi-encoder similarity from earlier\n",
    "print(\n",
    "    f\"Bi-encoder similarity: {similarity:.4f} (compares separate embeddings)\")\n",
    "print(\"The cross-encoder can capture more complex relevance patterns between query and document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. RETRIEVAL QUALITY COMPARISON\n",
      "-----------------------------\n",
      "Let's see how the document ranking changed after reranking:\n",
      "\n",
      "Changes in ranking:\n",
      "Document moved from position 3 to 2\n",
      "Document moved from position 2 to 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5. RETRIEVAL QUALITY COMPARISON\")\n",
    "print(\"-----------------------------\")\n",
    "print(\"Let's see how the document ranking changed after reranking:\")\n",
    "\n",
    "# Get the contents of top results from each method\n",
    "hybrid_contents = [node.node.get_content() for node in hybrid_results[:3]]\n",
    "reranked_contents = [node.node.get_content() for node in reranked_results[:3]]\n",
    "\n",
    "print(\"\\nChanges in ranking:\")\n",
    "for i, content in enumerate(reranked_contents):\n",
    "    if content in hybrid_contents:\n",
    "        old_rank = hybrid_contents.index(content) + 1\n",
    "        if old_rank != i + 1:\n",
    "            print(f\"Document moved from position {old_rank} to {i+1}\")\n",
    "    else:\n",
    "        print(f\"New document at position {i+1} (wasn't in top 3 before)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Considerations\n",
    "\n",
    "1. Latency-Quality Tradeoff:\n",
    "\n",
    "Reranking adds processing time (in our example, about 0.04 seconds)\n",
    "This overhead scales with the number of candidates being reranked\n",
    "Adjust fetch_k to balance between quality and performance\n",
    "\n",
    "2. Model Selection:\n",
    "\n",
    "Smaller cross-encoder models (like the one we used) are faster but less accurate\n",
    "Larger models provide better quality but with higher computational costs\n",
    "Consider distilled models that balance speed and accuracy\n",
    "\n",
    "3. Resource Requirements:\n",
    "\n",
    "Cross-encoders are more compute-intensive than bi-encoders\n",
    "GPU acceleration can significantly improve throughput\n",
    "Consider batching and asynchronous processing for efficiency\n",
    "\n",
    "4. Candidate Selection:\n",
    "\n",
    "The quality of reranking depends on having good initial candidates\n",
    "If the initial retrieval misses relevant documents, reranking can't fix it\n",
    "Always focus on improving both stages of the pipeline\n",
    "\n",
    "5. Result Diversity:\n",
    "\n",
    "Reranking can sometimes over-prioritize one aspect of relevance\n",
    "Consider adding diversity mechanisms if this is a concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
